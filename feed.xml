<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://collinjennings.com/feed.xml" rel="self" type="application/atom+xml"/><link href="https://collinjennings.com/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-06T19:27:25+00:00</updated><id>https://collinjennings.com/feed.xml</id><title type="html">blank</title><subtitle>#A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Aeon Article - A Linkless Internet</title><link href="https://collinjennings.com/blog/2024/aeonArticle/" rel="alternate" type="text/html" title="Aeon Article - A Linkless Internet"/><published>2024-12-06T14:27:24+00:00</published><updated>2024-12-06T14:27:24+00:00</updated><id>https://collinjennings.com/blog/2024/aeonArticle</id><content type="html" xml:base="https://collinjennings.com/blog/2024/aeonArticle/"><![CDATA[<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS87JiT8zhs5oyczdURgyW7G2ZuJRrd-yLPVQ&amp;s" alt="hypertext diagram"/> I have a <a href="https://aeon.co/essays/when-ai-summaries-replace-hyperlinks-thought-itself-is-flattened">new essay up over at Aeon</a>. I trace the intellectual history of hyperlinks as a way of considering what happens when links disappear in favor of AI chatbots.</p>]]></content><author><name></name></author><category term="blog"/><category term="ai"/><category term="links"/><category term="history"/><summary type="html"><![CDATA[I have a new essay up over at Aeon. I trace the intellectual history of hyperlinks as a way of considering what happens when links disappear in favor of AI chatbots.]]></summary></entry><entry><title type="html">The Frame of Reference: Solving Detective Stories with AI - #1</title><link href="https://collinjennings.com/blog/2024/detectiveExperimentPost-1/" rel="alternate" type="text/html" title="The Frame of Reference: Solving Detective Stories with AI - #1"/><published>2024-11-23T14:27:24+00:00</published><updated>2024-11-23T14:27:24+00:00</updated><id>https://collinjennings.com/blog/2024/detectiveExperimentPost-1</id><content type="html" xml:base="https://collinjennings.com/blog/2024/detectiveExperimentPost-1/"><![CDATA[<p><img align="right" alt="Holme's Speckled Band" src="https://media.licdn.com/dms/image/D5612AQHA__wDIO-E5w/article-cover_image-shrink_600_2000/0/1687677533378?e=2147483647&amp;v=beta&amp;t=Zbsh4vgwQwMZZRhEwxdGpvPefp0eQUj1yrPHO1_LgO0"/></p> <p>Before the detective story, there was the tale of ratiocination. This is what Edgar Allan Poe called his trio of short stories featuring, C. Auguste Dupin, an amateur detective before there was the word <em>detective</em>. Readers of detective stories likely know that Dupin provided the model for Sherlock Holmes and Hercule Poirot. Like Holmes’s “consulting detective” title, Dupin’s amateur status provides him a degree of remove for considering crimes from a different perspective than the police. When the Paris police prefect consults Dupin in “The Purloined Letter,” the officer explains that his men “search <em>every where</em>.” He declares,</p> <blockquote> <p>to a properly trained police-agent, such a thing as a ‘secret’ drawer is impossible.</p> </blockquote> <p>But from his distance, Dupin recognizes that the minister who has taken the letter knows that the police will search every potential hiding spot, so he leaves it in plain sight. The police treat every crime the same, but Dupin and his legion of amateur/consulting successors read the criminal not just the crime.</p> <p>Readers of detective fiction quickly come to recognize this trope among many others. We tend to think of the genre as highly conventional, and like Dupin, when we consider potential suspects, we often settle on the culprit based on our knowledge of the genre rather than the details of the case. We know, for instance, that we can eliminate whomever the police initially arrest; that character is ruled out based on how he’s treated by the story.</p> <p>I’ve been thinking about how we read detective stories in relation to a question about how large language models read more generally. This connection may seem strange, but it comes from the concept of attention. Attention is what allows Dupin to succeed where the Parisian police fail, and it is also what has produced the rapid advances in LLMs and AI in the last eight years. The basics of the story are that the 2017 article <a href="https://arxiv.org/abs/1706.03762">“Attention is All You Need,”</a> by Vaswani et al. introduced the <a href="https://en.wikipedia.org/wiki/Transformer_deep_learning_architecture">transformer</a> architecture, allowing models to process all the words of a text at once rather than in order. Models then iteratively assign and update the weights for measuring the relative importance of the words in determining what the text is saying. This method enabled researchers to train LLMs much more efficiently leading through the breakthroughs of ChatGPT and others.</p> <p>But how does this computational measure of attention resemble or differ from the attention we pay to language when we read? To answer this question, I decided to run an experiment to see if a popular, commercial LLM tends to pay attention like Poe’s detective or like the Parisian police. Can an LLM solve detective stories as well or better than human readers?</p> <h3 id="rationale">Rationale</h3> <p>The goal for the experiment is to see to what extent we can observe patterns in how a prominent LLM reads stories as a proxy for better understanding how the model works–that is, how it pays attention. The easiest way to figure out what an LLM pays attention to is to examine what it was trained on, but that’s not possible for commercial models and even if it were, the variety and volume of training data is so great that it would be difficult to do much with it. I wanted to try this experiment as an alternative approach to uncovering tendencies in how LLMs read stories.</p> <p>I settled on using detective short stories for a few reasons. The primary reason is that predicting the culprit of a detective story seems to sit between the kinds of tasks that LLMS are trained on (question answering, summarizing, etc.) and literary interpretation. Of course, this is very different from developing a close reading, but making a prediction entails producing a theory of the text that draws on both the details of the fictional crime and the devices of the story. The second reaon for detective stories is that there are well developed corpora with extensive metadata for the genre. Finally, detective stories tend to be short enough to be processed efficiently by commercial LLMs and even some open-source ones with smaller token limits.</p> <h2 id="methods">Methods</h2> <p>I got the idea for the experiment after stumbling upon a collection of detective stories that was prepared with fascinating metadata. This is <a href="https://github.com/ahmmnd/BMDS">“The Birth of the Modern Detective Story” dataset</a> produced by Adam Hammond et al. out of the University of Toronto. The corpus includes 435 stories published between 1891 and 1925. The metadata includes fields, such as <code class="language-plaintext highlighter-rouge">Reveal border sentence</code>, <code class="language-plaintext highlighter-rouge">Sufficient clues to solve?</code>, and <code class="language-plaintext highlighter-rouge">Correct annotator guess?</code>. These fields enable me, first, to crop the stories so that the model can only process the excerpt up until the reveal begins, and second, to compare the results of the model to those of the human annotators.</p> <p>After discovering the corpus, I had to decide which LLM to use. I first tried out several open-source/free models available on Hugging Face. Because of the specific nature of the task, it seemed easiest to use an instruction-interface model for I which I could provide a detailed prompt. I found the <a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1">Mistral Instruct 7B model</a> to be the most efficient and accurate, although it struggled to process longer stories.</p> <p>I tried ChatGPT 3.5 through the web interface on one story, but even with instructions to only use the provided text, it appeared to be drawing on outside knowledge – its predictions were just too good.</p> <p>I landed on <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Google’s Gemini model (specifically the 1.5 flash version)</a> because it processed the texts quickly, and its results indicated that it was <strong>not</strong> using information beyond the text. (At some point, I may try masking character names, but for now it seems unnecessary.)</p> <p>For the experiment, I provide the following prompt:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>qa_prompt = """Read the excerpt from a detective story, and predict who committed the crime.
The perpetrator is not identified in this portion of the story. The story may try to trick you with red herring clues.
Make sure to predict something that has not already happened. Then identify one key piece of evidence (consider material and testimonial clues) that supports your prediction."""
</code></pre></div></div> <p>I tried to provide clear instructions without putting my thumb on the scale in terms of what the model should focus on in making its prediction. I suggest kinds of clues to consider and even certain genre features, but I have found that these instructions don’t impede the model from grabbing for the most obvious clues. I combine the prompt with several correct examples that include the prediction and key piece of evidence. This few-shot prompting technique produces more accurate results, but it does prime the model to focus on certain kinds of evidence.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">### Few-shot examples 
</span><span class="n">text</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="sh">"""</span><span class="s"> Given the fields </span><span class="sh">"</span><span class="s">Context</span><span class="sh">"</span><span class="s"> and </span><span class="sh">"</span><span class="s">Question</span><span class="sh">"</span><span class="s">, produce the fields </span><span class="sh">"</span><span class="s">Prediction</span><span class="sh">"</span><span class="s"> and </span><span class="sh">"</span><span class="s">Evidence</span><span class="sh">"</span><span class="s">.
---
</span><span class="sh">"</span><span class="s">Context</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">metaList</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Question</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">qa_prompt</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Prediction</span><span class="sh">"</span><span class="s">: The perpetrator is the trainer John Straker himself, and Silver Blaze killed him by kicking the trainer in self-defense.
Evidence: The key clue is cataract knife which he took with him to
intentionally injure the horse, rather than for self defense.

---
</span><span class="sh">"</span><span class="s">Context</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">metaList</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Question</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">qa_prompt</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Prediction</span><span class="sh">"</span><span class="s">: Arthur Pinner, the brother of Harry Pinner, is the perpetrator. He likely orchestrated the entire scheme to defraud
the firm Pycroft was hired to, and the suicide attempt was a final act of desperation when his plan was discovered.
</span><span class="sh">"</span><span class="s">Evidence</span><span class="sh">"</span><span class="s">: The fact that both brothers have the same gold-filled tooth is a strong indicator that they are not who they claim
to be. This suggests a deliberate attempt to deceive Hall Pycroft.

---
</span><span class="sh">"</span><span class="s">Context</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">metaList</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="sh">'</span><span class="s">text</span><span class="sh">'</span><span class="p">]</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Question</span><span class="sh">"</span><span class="s">: </span><span class="si">{</span><span class="n">qa_prompt</span><span class="si">}</span><span class="s">,
</span><span class="sh">"</span><span class="s">Prediction</span><span class="sh">"</span><span class="s">:
</span><span class="sh">"</span><span class="s">Evidence</span><span class="sh">"</span><span class="s">:

</span><span class="sh">"""</span>

</code></pre></div></div> <p>After the model makes prediction and offers supporting evidence, I compare it to the response of the human annotators according to,</p> <ul> <li><strong>Accuracy</strong> - Was the prediction correct? Does the supporting evidence match the key clues identified by the annotator?</li> <li><strong>Solvability</strong> - The annotators indicated whether the crime was “guessable,” “solvable,” and if they accurately guessed the culprit. I give 1 point for each field to create a solvability spectrum that goes from 0 to 3 as a way to measure how predictable the culprit is.</li> </ul> <h2 id="proof-of-concept">Proof-of-concept</h2> <p>I’ve run the experiment on all the Sherlock Holmes stories in the corpus with results for 39 stories. (This excludes stories in which a crime isn’t solved (e.g., “The Final Problem) or in which the identity of the culprit is known from the outset (e.g., “Mazarin Stone”). Gemini accurately predicted the culprit about 62% of the time compared to 26% percent for the human annotators. (I’m not very interested in this part of the comparison if only because I don’t think accurately guessing the perpetrator was a focus for the human annotators; it seems like it was incidental to the larger process of producing the metadata for the detective story corpus.) For the sake of space, I am going to wait until my next post to examine the full results. For now, I want to consider a couple examples that I’m using to develop a hypothesis regarding the results for the full corpus.</p> <p>My working theory is that the model does well with stories that feature clear, “decodable” clues, and it struggles with ones that depend more upon genre conventions. I’m taking the term “decodable” from Franco Moretti’s essay, <a href="https://read.dukeupress.edu/modern-language-quarterly/article-abstract/61/1/207/19219/The-Slaughterhouse-of-Literature?redirectedFrom=fulltext">“The Slaughterhouse of Literature,”</a> in which he organizes early detective stories on a spectrum relative to their use of clues, ranging from <strong>present</strong>, to <strong>necessary</strong>, to <strong>visible</strong>, to <strong>decodable</strong>. The model correctly predicts the culprit for all the stories in which Moretti identifies decodable clues. “The Adventure of the Speckled Band” is one of these stories. Here’s the model’s prediction:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Answer: {"Prediction": "Dr. Grimesby Roylott is the perpetrator. He used a snake to kill his stepdaughter Julia and is now attempting to kill Helen.", "Evidence": "The dying words of Julia, 'Oh, my God! Helen! It was the band! The speckled band!' strongly suggest that a snake was involved. The 'speckled band' likely refers to a venomous snake, and the 'band' could be a snake charmer's band or a group of snakes. The fact that Dr. Roylott has a passion for Indian animals, including a cheetah and a baboon, further supports the theory that he might have access to venomous snakes. The presence of the dog lash tied into a loop, which Holmes finds in Dr. Roylott's room, is a crucial piece of evidence. It suggests that the lash was used to control the snake, possibly to guide it through the ventilator and into Julia's room."}
</code></pre></div></div> <p>This makes sense, and it resembles the human annotators key clue (<code class="language-plaintext highlighter-rouge">“The chair in the stepfather's room with the lash under it”</code>). The model seems to get to the right prediction via a route similar to human readers. However, I think the way the model is wrong is more interesting. The model seems to be terrible at reading for genre. As I remarked above, one of the first things a practiced human reader does when reading a detective story is to dismiss the suspect arrested by the police. Often how the story treats the characters is the most reliable way to predict the culprit regardless of the circumstantial evidence. In “Silver Blaze,” as Holmes briefs Watson on the details of the case, he remarks of the official investigator:</p> <blockquote> <p>‘Inspector Gregory, to whom the case has been committed, is an extremely competent officer. Were he but gifted with imagination he might rise to great heights in his profession. On his arrival he promptly found and arrested the man upon whom suspicion naturally rested.’</p> </blockquote> <p>The suspect is Fitzroy Simpson, who had visited the horse stables near where the horse trainer John Straker was later found dead and the prize racehorse (the eponymous Silver Blaze) went missing. The most obvious clues point to Simpson, but Holmes has already in effect told the reader that he is innocent. Here’s the model’s prediction:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Answer: {"Prediction": "The perpetrator is Fitzroy Simpson. He likely killed Straker to cover up his theft of Silver Blaze.", "Evidence": "The key clue is the fact that Fitzroy Simpson's cravat was found in the dead man's hand. This suggests a struggle between the two, and that Simpson was present at the scene of the crime."}
</code></pre></div></div> <p>What also makes “Silver Blaze” difficult for the model (and for readers) is that the story plays with the conventions of detective stories even as an early example of the genre. The culprit turns out to be the victim, Straker. Holmes explains during the reveal that the key clues are the cataract knife that Straker had with him and a receipt found in his house showing the purchase of expensive women’s clothing under a different name. It turns out that Straker had a mistress and an assumed identity under which he had accrued a large debt, and to manage this debt, he planned to wound Silver Blaze and win a large bet placed on the horse’s chief rival. Before Straker has the opportunity to wound the horse, however, Blaze kicks him in the head and flees. The story subverts the reader’s/model’s expectations, but it also refers back to the detective story’s origin with Poe. The animal as murderer recalls Poe’s first Dupin detective story, “The Murders in the Rue Morgue,” in which the detective solves a seemingly inexplicable murder by discovering that it had been committed by an escaped orangutan.</p> <p>The title of this post is a nod to Barbara Johnson’s essay <a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/http://ereserve.library.utah.edu/Annual/ENGL/6670/Margolis/frameof.pdf">“The Frame of Reference: Poe, Lacan, Derrida“</a> in which she analyzes Derrida’s critique of Lacan’s reading of Poe’s “Purloined Letter.” As that series of phrases suggests, reflexivity is both a feature of the detective story genre and the practice of reading detective stories. Johnson accuses Derrida of the same blindspots that he attributes to Lacan. I’m left wondering if genre is a blindspot for Google’s AI and what that would mean for how we understand AI. In her essay, Johnson pauses on the Dupin’s epigraph that he leaves for the minister in place of the purloined letter. It is a line from Crébillon’s play <em>Atrée et Thyeste</em>:</p> <blockquote> <p>“So bale a plan, if unworthy of Atreus, is worthy of Thyestes.”</p> </blockquote> <p>Like “The Purloined Letter,” Crébillon’s play is the “story of revenge as symmetrical repetition of the original crime” that is incited by a stolen letter. Johnson observes that Poe’s story is a “story of repetition” that is “itself a repetition of the story from which it purloins its last words.” All of this is to say that the founding moves of detective fiction are repetition and intertextuality. I have found that Google’s model tends to fall for red herrings and to select the most obvious (and thereby often wrong) suspects. As I move to the next phase of the experiment, I’m going to try to test this hypothesis across the corpus. If Google’s Gemini struggles to notice genre tropes, then it would seem to struggle with detective stories as the genre evolved and developed in the early 20th century. I’m now trying to think about what it would look like to test this hypothesis. (If you have any ideas, drop me a note!)</p> <p>In the next post, I will analyze Gemini’s predictions across the entire Sherlock Holmes short story corpus before turning to the full detective story set. The code used for this experiment is available <a href="https://github.com/collinjennings/detectiveLLMs/blob/main/solvingDetectiveStoriesAI.ipynb">here</a>.</p>]]></content><author><name></name></author><category term="blog"/><category term="ai"/><category term="genre"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">The History of Literature Podcast - Mind and Media in the Enlightenment</title><link href="https://collinjennings.com/blog/2024/history-literature/" rel="alternate" type="text/html" title="The History of Literature Podcast - Mind and Media in the Enlightenment"/><published>2024-11-17T16:40:16+00:00</published><updated>2024-11-17T16:40:16+00:00</updated><id>https://collinjennings.com/blog/2024/history-literature</id><content type="html" xml:base="https://collinjennings.com/blog/2024/history-literature/"><![CDATA[<p>I recently discussed [‘Enlightenment Links’ with Jacke on ‘The History of Literature’ podcast!] (https://www.historyofliterature.com/649-mind-and-media-in-the-enlightenment-with-collin-jennings-mike-recommends-a-moveable-feast-by/) Check it out!</p>]]></content><author><name></name></author><category term="news"/><category term="talks"/><summary type="html"><![CDATA[I recently discussed [‘Enlightenment Links’ with Jacke on ‘The History of Literature’ podcast!] (https://www.historyofliterature.com/649-mind-and-media-in-the-enlightenment-with-collin-jennings-mike-recommends-a-moveable-feast-by/) Check it out!]]></summary></entry><entry><title type="html">Stats + Stories Podcast - “Judging Words by the Company They Keep”</title><link href="https://collinjennings.com/blog/2023/stats-stories/" rel="alternate" type="text/html" title="Stats + Stories Podcast - “Judging Words by the Company They Keep”"/><published>2023-03-16T16:40:16+00:00</published><updated>2023-03-16T16:40:16+00:00</updated><id>https://collinjennings.com/blog/2023/stats-stories</id><content type="html" xml:base="https://collinjennings.com/blog/2023/stats-stories/"><![CDATA[<p>I was excited to join the <a href="https://statsandstories.net/methods/judging-words-by-the-company-they-keep"><strong>Stats + Stories</strong> podcast</a> to discuss my book <em>Enlightenment Links</em> as well as why computational methods matter for studying literature.</p>]]></content><author><name></name></author><category term="news"/><category term="talks"/><summary type="html"><![CDATA[I was excited to join the Stats + Stories podcast to discuss my book Enlightenment Links as well as why computational methods matter for studying literature.]]></summary></entry><entry><title type="html">The Language of Notation and Imaginative Writing</title><link href="https://collinjennings.com/blog/2020/language-notation/" rel="alternate" type="text/html" title="The Language of Notation and Imaginative Writing"/><published>2020-07-22T14:27:24+00:00</published><updated>2020-07-22T14:27:24+00:00</updated><id>https://collinjennings.com/blog/2020/language-notation</id><content type="html" xml:base="https://collinjennings.com/blog/2020/language-notation/"><![CDATA[<p>What are the conditions under which very different words are brought together in writing? Are varied word combinations predisposed to particular genres or discourses? Are there types of words that could be said to constitute lexical situations that would not otherwise occur? And, when words that are not typically used in the same context co-occur, what are they doing? I am going to report the results of a text analysis experiment designed to begin to address these questions. Recent advances in semantic modeling (from topic modeling to word embeddings) make it relatively easy to describe the statistical likelihood of a given set of words to co-occur. Methods in semantic modeling start from the premises that words tend to occur in particular linguistic contexts, and we can decipher the meaning of an unknown word based upon the words that appear near it. While many humanists (like me) interested in text analysis have begun to explore the mathematics of operationalizing these premises, corpus linguists have been thinking about modeling language in this way since the 1940s and 50s. Early theorist of the “distributional structure” of language, Zellig Harris, explains that, “The perennial man in the street believes that when he speaks he freely puts together whatever elements have the meanings he intends; but he does so only by choosing members of those classes that regularly occur together and in the order in which these classes occur.”<a href="#fn0"><sup>1</sup></a><a href="#fn0"></a> His contemporary, J. R. Firth, put the claim even more plainly in his now famous formulation: “You shall know a word by the company it keeps.”<a href="#fn1"><sup>2</sup></a><a href="#fn1"></a> Since these foundational theories, linguists have produced methods for mathematically representing the tendencies of language. In this experiment, I focus on word space models, which represent the distribution of words in a corpus as vectors with hundreds or thousands of dimensions wherein proximity in the vector space corresponds to semantic similarity. The vector position for any given word represents a probabilistic profile regarding the lexical contexts in which one would expect to find that word. As a consequence, word vectors can be added and subtracted to find the words most similar in the model to the resulting composite vector.</p> <p><em>Two different semantic contexts of ‘bounds’</em> - The values appearing next to the resulting words refer to the cosine similarity score between the composite vector (produced by adding the positive word vectors and subtracting the negative one) and the most similar word vectors in the word space model. The score indicates the proximity of the vectors in the model, which should correspond to their semantic similarity—the closer to 1, the more similar words.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">bounds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">leaps</span><span class="sh">'</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">limits</span><span class="sh">'</span><span class="p">])[:</span><span class="mi">6</span><span class="p">])</span>
<span class="nf">print</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">bounds</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">limits</span><span class="sh">'</span><span class="p">],</span> <span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">leaps</span><span class="sh">'</span><span class="p">])[:</span><span class="mi">6</span><span class="p">])</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[('skips', 0.5588804483413696), ('leap', 0.5247325897216797), ('leapt', 0.5211300253868103), ('skipping', 0.5187863111495972), ('flings', 0.5138592720031738), ('alights', 0.5134779810905457)]

[('boundaries', 0.6185899376869202), ('limited', 0.595120906829834), ('limit', 0.5744596719741821), ('precincts', 0.5576064586639404), ('confined', 0.5283891558647156), ('confine', 0.5277968645095825)]
</code></pre></div></div> <p>Any particular phrase or sentence will feature word combinations that more or less correspond to linguistic patterns represented in the word space model. Defining expectation in terms of the proximity between word vectors, what are the contexts in which unexpected words tend to occur? Do they appear in particular places, like those rare neighborhood bars that attract patrons across a wide demographic range? Or are aberrational word groupings brought together by specific terms, like Prince or Beyoncé drawing fans from all backgrounds?</p> <p>I come to semantic modeling from a literary perspective. I initially started to think about measures for unusual linguistic situations as potentially indexing the appearance of literary tropes and figures. It’s a simplistic hypothesis, but it still seems reasonable to expect that unusual word combinations may be responsible for literal and figurative dimensions of meaning. The term <em>heart</em> often appears in discussions of biology as well as love; thus it may also appear in a context wherein both connotations obtain. Literary scholars have recently used semantic modeling to observe genre differences between fiction, poetry, and non-fiction as well as between sub-genres of the novel or particular forms of poetry during different historical periods.<a href="#fn2"><sup>3</sup></a><a href="#fn2"></a> This experiment draws upon this previous work but frames the critical questions both more narrowly and broadly in particular ways. On the one hand, I’m looking at the co-occurrence of words on the level of the sentence. Given the distribution of words across a large corpus, how likely are the words in a given sentence to co-occur? On the other hand, I’m considering all of the sentences in a corpus (rather than focusing on specific genres) in order to move from mathematical properties of word distributions to observations about how those properties manifest as linguistic functions in different discursive contexts. From this perspective, it is not at all clear that literary texts would stand out from a broader print environment in the ways we might expect. Literary, or imaginative, writing may even appear more formulaic and orderly than written forms that rely on direct, empirical observation. (I’ll be primarily using <em>imaginative writing</em> in place of the term <em>literature</em> since the latter is anachronistic for the seventeenth-century corpus used in this experiment.) According to the literary theorist Roland Barthes, the challenge for the novel writer, for one, concerns, “how to pass from Notation, and so from the Note, to the Novel, from the discontinuous to the flowing (to the continuous, the smooth [au nappé])?”<a href="#fn3"><sup>4</sup></a><a href="#fn3"></a> Notation here refers to annotating one’s experience—recording a series of events and thoughts that appear together without the linguistic architecture that gives language the statistical character that Harris and Firth describe. Translating the discontinuous record of consciousness into linear prose means moving “from the fragment to the nonfragment” (18).</p> <p>As the title of this post suggests, notation turns out to be very useful for explaining how the most unlikely linguistic situations are produced and organized in my corpus. I’m working with the publicly released portion of the <a href="http://www.textcreationpartnership.org/tcp-eebo/">Early English Books Online Text-Creation Partnership (EEBO-TCP)</a>, which consists of about 25,000 texts printed between 1475 and 1700. For this corpus, the preliminary answer to my opening string of questions is: there are particular terms that appear in the context of highly varied lexical contexts much more frequently than others, and these tend to be notational terms operating in a range of technical discourses (including heraldry, medicine, ornithology, and botany among others). Notation often refers to specific systems of signs and symbols used within a discipline like mathematics or music, but it can also be used in the manner that Barthes uses it above, to mean note-taking or annotating more generally. Most of the terms and contexts that I will present are best characterized by the first definition, but I will be using notation broadly to encompass both possible meanings because they each refer to processes of collecting unlike things—quantities, ideas, or observations—producing what Barthes calls “a layered text, a histology of cutups, a palimpsest.”<a href="#fn4"><sup>5</sup></a><a href="#fn4"></a> In seventeenth-century English print, the language of notation performs this function by serving as a linguistic framework of arrangement and combination (as in a list of ingredients for a medical recipe) without requiring the grammatical entailments of linear prose. Considered from a literary historical perspective, the linguistic work of notation offers a useful point of contact for thinking about forms of abstraction and comparison, which produce the conditions under which disparate things are brought together in language. In the case of imaginative writing, we typically ascribe such tasks to tropes and figures, but critical theorists like Barthes and more recently literary historians, including Henry Turner, Elaine Freedgood, and Cannon Schmidt have drawn attention to the function of “technical, denotative, and literal” language in literary works.<a href="#fn5"><sup>6</sup></a><a href="#fn5"></a> As I unpack the results of this experiment, I will locate different forms of notation in relation to this critical conversation in order to highlight the imaginative functions of this mode of arranging language.</p> <p>I produced a 300-dimension word space model of a portion of the EEBO-TCP corpus (all of the texts printed between 1640 and 1700, from the English Civil Wars through the Restoration and Revolution of 1688, consisting of 18,752 texts) using the <a href="https://en.wikipedia.org/wiki/Word2vec"><code class="language-plaintext highlighter-rouge">word2vec</code></a> package in python. (I will refer to this as my Restoration model.)<a href="#fn6"><sup>7</sup></a><a href="#fn6"></a> <code class="language-plaintext highlighter-rouge">Word2Vec</code> uses a “shallow” neural network to generate a predictive word distribution model, rather than a count-based model. This approach makes it more efficient and easier to train, and some computer scientists argue that predictive word space models perform better than count-based ones, but this is a highly contested argument.<a href="#fn7"><sup>8</sup></a><a href="#fn7"></a> The challenge of using a predictive model for dealing with historical semantics, however, is that the training process makes it difficult to track how a term’s vector profile changes over time. To deal with this issue, I’ve taken a five-year subset (from 1678-1682, during the period of the Popish Plot and Exclusion Crisis in England) of the corpus used to train the model, so that I can compare the usage of words in the subset to their vector profiles in the larger Restoration model. The experiment that I present here then considers which words, occurring in texts printed between 1678 and 1682, tend to appear in contexts featuring the most varied combinations of terms relative to the larger Restoration model. While the results only directly refer to the five-year window of the subset, they appear to indicate a pattern that holds for most of the 1670s and 80s, based on other early investigations.</p> <p>In order to identify these results, I developed an average standard deviation measure (in collaboration with <a href="http://modelingliteraryhistory.org/">Michael Gavin</a>) that takes every context window for a given term in the five-year subset and finds the standard deviation between each vector position across the 300 dimensions for each word vector that co-occurs in a particular context window. The measure returns the standard deviation of the word vectors in a context window of the term, and that measure is averaged across all of the context windows for the term. The average standard deviation value then provides a proxy for determining how varied the lexical contexts tend to be for each term in the subset corpus (normalized to remove rare terms).<a href="#fn8"><sup>9</sup></a><a href="#fn8"></a> I also explored a method that used the average cosine similarity scores between a key term and the words in its context windows, which represents how likely that particular term would appear within its different contexts. The standard deviation measure, however, represents the variation between all of the words of the context window alone. As a consequence, the top scoring terms for the measure are not necessarily words that appear in the widest range of contexts; instead, the top terms are words that tend to appear in the most uncommon contexts in the subset overall. These are the words that most frequently occur at the center of rare word sequences.</p> <p>To see what this looks like, here are the top 50 terms returned for the average standard deviation measure for the 1678-1682 subset corpus:</p> <h2 id="top-50-terms-for-average-standard-deviation-measure">Top 50 terms for average standard deviation measure</h2> <p><img src="/assets/top_words.png" alt="terms"/></p> <p>Since I am using a seventeenth-century corpus that includes Latin, English, and French texts including non-standardized spelling, these results look a bit inscrutable at first. I’ve gone through the most common texts in which each term appears in the corpus, and here is a breakdown of the different kinds of words in the top 50 that makes it easier to observe similarities across the terms:</p> <h2 id="word-types-in-the-top-50-terms">Word Types in the Top 50 Terms</h2> <p><img src="/assets/pieChart.png" alt="pie"/></p> <p>From these types, I can make some basic observations. First, the terms primarily come from different technical discourses, including medicine, natural philosophy/alchemy, and cooking/agriculture. These tend to be learned contexts featuring a high prevalence of abstruse language. In part because of the association with expert communities, the terms appear in genres that often combine English and Latin. While I was initially tempted to dismiss Latin terms because they appear in a foreign language context (and thus will unavoidably seem more varied in relation to a primarily English corpus), the Latin words are often performing a similar semantic function to the English terms on the list. Of course, the foreign language context is still a factor here, but I will suggest below that it’s not sufficient to explain the placement of the top terms on the list. What’s more is that it’s not practical to simply remove the Latin texts from the corpus because most of the terms are coming from genres that contain Latin and English in the same context, such as botany and ornithology. An unavoidable feature of seventeenth-century English print is that it is a multilingual environment.</p> <h2 id="cluster-of-top-150-terms-appearing-in-the-most-varied-contexts">Cluster of Top 150 Terms appearing in the Most Varied Contexts</h2> <p>To gain more context regarding the sources of the terms, I performed K-means cluster analysis on all of the context windows for the top 150 terms. This meant treating all of the context windows for each term as a single document and then seeing which of the ‘term documents’ are the most similar. This is not far off from the logic behind training a word vector model, and it similarly produces a result in which words that appear in similar contexts are located near one another and far from words appearing in dissimilar contexts. In the two-dimensional representation of the clusters, we can see that <em>bushel</em>, <em>bushels</em>, <em>wheat</em>, and <em>barly</em> are near one another in the upper-left corner, and <em>fraction</em>, <em>numerator</em>, and <em>denominator</em> are clustered in the bottom-right corner. In the <code class="language-plaintext highlighter-rouge">word2vec</code> model, <em>fraction</em> returns a similarity score of 0.81 with <em>numerator</em> and 0.82 with <em>denominator</em>, and <em>numerator</em> and <em>denominator</em> return a score of 0.94—all of which indicate very high semantic similarity between the terms and thus suggest that the k-means graph accurately reflects the proximity between terms in the larger word space model.<br/> <img src="/assets/kmeansNotation.png" alt="top terms"/></p> <p>In k-means clustering (as with many topic modeling algorithms), the user has to select the number of clusters, and here I settled on four after identifying the top texts in which the words appeared in the subset. There appear to be four loose discourses in which these terms primarily occur. The table below breaks down the contents of these discourses:</p> <table class="mbtablestyle"> <thead> <tr> <th style="text-align: center">Cluster</th> <th style="text-align: center">Discourse</th> <th>Exemplary Titles</th> <th style="text-align: center">Top Terms</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><strong>Green</strong></td> <td style="text-align: center">Latin texts primarily on botany and natural history</td> <td>Robert Morison, <em>Plantarum historiæ universalis Oxoniensis. Pars secunda seu herbarum distributio nova, per tabulas congnationis &amp; affinitatis ex libro naturæ observata &amp; detecta</em> (1680)</td> <td style="text-align: center">folio, sine, sit, major, species, minor, anno, sex, alias</td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td>Sir Robert Sibbald, <em>Scotland illustrated, or, An essay of natural history in which are exquisitely displayed the nature of the country, the dispositions and manners of the inhabitants…and the manifold productions of nature in its three-fold kingdom, (viz.) vegetable, animal and mineral, dispersed throughout the northern part of Great Brittain</em> (1684)</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center"><strong>Orange</strong></td> <td style="text-align: center">Orinthology</td> <td>John Ray, <em>The ornithology of Francis Willughby of Middleton in the county of Warwick Esq, fellow of the Royal Society in three books : wherein all the birds hitherto known, being reduced into a method sutable to their natures, are accurately described</em> (1678)</td> <td style="text-align: center">feathers, white, black, colour, middle, tips, dusky, exteriour, outmost</td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td>John Josselyn, <em>New-Englands rarities discovered in birds, beasts, fishes, serpents, and plants of that country</em> (1672)</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center"><strong>Pink</strong></td> <td style="text-align: center">Heraldry</td> <td>Sir George Mackenzie, <em>The science of herauldry, treated as a part of the civil law, and law of nations wherein reasons are given for its principles, and etymologies for its harder terms.</em> (1680)</td> <td style="text-align: center">three, argent, betwixt, azur, sable, bend, within, beareth, quartered</td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td>Robert Thoroton, <em>The antiquities of Nottinghamshire extracted out of records, original evidences, leiger books, other manuscripts, and authentick authorities : beautified with maps, prospects, and portraictures</em> (1677)</td> <td style="text-align: center"> </td> </tr> <tr> <td style="text-align: center"><strong>Purple</strong></td> <td style="text-align: center">Chemistry, medicine, and recipe books</td> <td>Moses Charras, <em>The Royal Pharmacopoea; Galenical and Chemical, according to the practice of the the most eminent and learned physicians of France</em> (1678)</td> <td style="text-align: center">half, ounce, two, dram, three, iij, bushels, ounces</td> </tr> <tr> <td style="text-align: center"> </td> <td style="text-align: center"> </td> <td>George Hartman, <em>The true preserver and restorer of health being a choice collection of select and experienced remedies for all distempers incident to men, women, and children: selected from and experienced by the most famous physicians and chyrurgeons in Europe: together with Excellent directions for cookery</em> (1682)</td> <td style="text-align: center"> </td> </tr> </tbody> </table> <p><br/> Above I observed the prevalence of terms from technical discourses, and here we can see the kinds of texts in which these discussions occur. The titles indicate writers attempting to share different bodies of knowledge using specific taxonomies and systems of notation, as illustrated in the “science of herauldry” and an “essay of natural history.” The taxonomies are often attributed to a particular person or group, which creates the need to translate an individual system into the terms of a larger domain of shared knowledge. The top terms indexing the most varied contexts for each discourse include adjectives and numbers, but the most common type of terms, appearing across the clusters, are ones that seem to function as common ligatures used in descriptions of different cases and examples positioned within the respective taxonomies and systems. In ornithology, all species of birds have an <em>exterior</em>, <em>feathers</em>, and <em>tips</em> with features that are <em>outmost</em> or in the <em>middle</em>. Likewise, in natural histories written in Latin, different species are arranged in hierarchical structures with <em>major</em> and <em>minor</em> divisions. The purple cluster features a large amount of mathematical (<em>fraction</em>, <em>denominator</em>) and natural philosophical (<em>vitriolated</em>, <em>pulverized</em>) terms but also a significant number of units of measure and symbols (<em>ounces</em>, <em>drams</em>, <em>gallons</em>, <em>iij</em>, <em>aq</em>). While the latter terms belong to specific notational systems, the former also tend to appear in notational contexts.</p> <p>Turn to particular passages with high frequencies of notational terms, and one can observe the linguistic and epistemological functions that they perform to make highly varied contexts possible. Notational terms provide the linguistic mortar for producing technical conventions—the descriptors, transitions, and abstract units that recur in lists and tables of various early modern knowledge domains. Take the following recipe for a Powder of Crabs-Claws from <em>The Royal Pharmacopoea</em> (1678). The recipe is set apart from the main text as a list, written in Latin and English in side-by-side columns, with each unit of the ingredients expressed in various apothecary symbols. Although in typical conversation or writing a seventeenth-century Briton would be unlikely to mention <em>river crabs-eyes</em>, <em>white amber</em>, <em>deer’s heart-bone</em>, and <em>saffron</em> in the same context, the genre of the recipe and the notational format that accommodates it make these very unlike objects linguistically and literally combinable.</p> <p><img src="/assets/crabRecipe.png" alt="Crab claw powder screenshot" title="Moyse Charas, *The Royal Pharmacopoea*, (London: 1678)"/></p> <p>In a radically different context, we can observe key terms from heraldry performing a similar function in the description of various coats of arms. Like the recipe, the table of noblemen and their coats of arms is represented in a distinctive printed form—set apart and arranged in a orderly manner, and, as in the recipe, there are particular recurring terms indicating the similarities across various coats even if the contents of the individual coats would be unlikely to appear together in a different context. These terms describe common colors and forms: for instance, <em>arg.</em> (the abbreviation for <em>argent</em> meaning <em>silver</em>), <em>passant</em> (the term for animals depicted in a walking position), and <em>azure</em>, as well as other terms, such as <em>betwixt</em> and <em>within</em>, indicate common prepositions used to link the different components of the coats.</p> <p><img src="/assets/coat_table.png" alt="Coat of arms table" title="Thomas Fuller, *The history of the worthies of England who for parts and learning have been eminent in the several counties : together with an historical narrative of the native commodities and rarities in each county*, (London: 1662)"/></p> <p>Across disciplinary contexts, notation operates as a form of writing for translating subjective, potentially idiosyncratic observations into shared, intelligible systems of arrangement. Previous discussions of notation from a literary theoretical vantage have emphasized the “reality effect”<a href="#fn9"><sup>10</sup></a><a href="#fn9"></a> produced by including denotative details in fictional contexts, and, more recently, Elaine Freedgood, Cannon Schmitt, and others have explored the potential for “literalist” readings of denotative language in literary texts.<a href="#fn10"><sup>11</sup></a><a href="#fn10"></a> A literalist reading relies on tracking down references to outside knowledge domains, such as discussions of coal mining in Emile Zola’s <em>Germinal</em> or scientific language in George Elliot’s novels. This approach recognizes that insofar as novelists and poets represent characters participating in practices and crafts of the world, they unavoidably and intentionally introduce disciplines foreign from the experience of the reader. Like systems of notation, literary genres bring together disparate ideas and things. In highlighting notational language in non-literary contexts, I’m not suggesting that one should read recipes, blazons, or scientific tables as literary texts. Instead, I’m attempting to point out that notational contexts perform literary functions of combination, abstraction, and comparison, and recognizing such functions suggests new ways forward in describing how literary tropes and figures operate in relation to the layered format of notational lists and charts.</p> <p>Consider my favorite exemplary passage of notational language, a recipe for a horse-hoof unguent that appears in a 1686 hunting manual, called <em>The Gentleman’s Recreation</em>. <img src="/assets/horse_unguent.png" alt="passage" title="Nicholas Cox, The Gentleman's Recreation, (London: 1686)"/></p> <p>The list of ingredients includes items that are familiar to us but would have been relatively novel to seventeenth-century readers (such as <em>turpentine</em>, which seems to have grown in popularity in the period) as well as objects completely foreign to us but very popular in the period (such as <em>trayn oil</em>). (Not to mention ones that are just baffling like <em>dog’s grease</em>, which turns out to be exactly what it sounds like.) These distinctive relationships between the objects in the recipe and our historical perspective indicate the varied meanings of the objects, beyond semantic significance. An item like train oil, which was produced by harvesting the fat from whale or cod, registers multiple dimensions of meaning in social and political domains in addition to linguistic ones. Indeed, historian K. G. Davies reports that in the 1680s, the Dutch government sent almost 2,000 whaling ships to Greenland to catch 10,000 whales for the production of train oil.<a href="#fn11"><sup>12</sup></a><a href="#fn11"></a> The combination of highly varied words in this example supports the idea that the lexical variation accommodated by notational contexts corresponds to related non-linguistic features—so-called real world consequences. The recipe bears out Barthes’s view of notation as “palimpsest,” wherein multiple semantic domains correspond to multiple historical temporalities. The constellation of disparate ingredients brings together the cultural, social, economic, and colonial histories of early modern Europe. At the moment of composition, the recipe conveyed a technique for creating a new substance out of many different ones, but as a historical document it represents a unique juncture, indicating something that could only have been conceived at a specific moment in time.</p> <p>The larger point is that the linguistic work of gathering together very different words indexes many more types of work that extend beyond the page and are implied by the histories of the objects and systems of notation represented. This linguistic phenomenon represents one answer to the question posed by Bruno Latour, “<em>how do we pack the world into words?</em>”<a href="#fn12"><sup>13</sup></a><a href="#fn12"></a> From a literary studies angle, I would slightly reframe the question to ask, how does imaginative writing pack the world into words similarly or differently from other modes and genres? In a discussion of mathematical thinking and the imagination, Arielle Saiber and Henry Turner posit that “imagination is that faculty of thinking that facilitates movement across systems of explanation that seem irreconcilable, and that, as a consequence, allows for new thoughts, new arguments, and new explanations to occur.”<a href="#fn13"><sup>14</sup></a><a href="#fn13"></a> If this is the case, then what are the linguistic structures and tropes that make this movement possible? This experiment regarding lexical variation and word space models illustrates how the language of notation contributes to such movement. How might we identify other contributors and the imaginative work they accomplish?</p> <h2 id="references">References</h2> <p><a id="fn0"></a>    1. Zellig Harris, “Distributional Structure,” <em>The Structure of Language: Readings in the Philosophy of Language</em>, ed. Jerry A. Fodor and Jerrold J. Katz (Englewood Cliff, NJ: Prentice-Hall, 1964), 34.</p> <p><a id="fn1"></a>     2. J. R. Firth, <em>Papers in Linguistics,1934–1951</em> (London: Oxford University Press, 1957), 11.</p> <p><a id="fn2"></a>     3. Roland Barthes, <em>The Preparation of the Novel: Lecture Courses and Seminars at the Collège de France</em> [2003], 3rd ed. (New York: Columbia University Press, 2010), 18. Also for an extended analysis of how Barthes’s understanding of notation changed from “The Reality Effect” essay to The Preparation of the Novel lectures, see Rachel Sagner Buurma and Lauren Heffernan, “Notation After ‘The Reality Effect’: Remaking Reference with Roland Barthes and Sheila Heti,” <em>Representations</em> 125.1 (Winter, 2014), 80-102. This essay appears in the fantastic special issue of <em>Representations</em> on denotative and technical language in the novel. I cite the introduction below.</p> <p><a id="fn3"></a>     4. There’s of course a lot of great recent critical work using semantic modeling. For topic modeling, the <a href="http://journalofdigitalhumanities.org/2-1/topic-modeling-and-digital-humanities-by-david-m-blei/"><em>Journal of the Digital Humanities</em></a> 2.1 (Winter, 2012), special issue on the subject is a great place to start. For thinking about, linguistic patterns on the scale of the sentence, see Sarah Allison, et al., <a href="https://litlab.stanford.edu/LiteraryLabPamphlet5.pdf">“Pamphlet 5: Style ate the Scale of the Sentence”</a>,” (June 2013)[lit lab]. Useful introductions to word embeddings include Lynn Cherney’s site word embedding version of <a href="http://www.ghostweather.com/files/word2vecpride/">“<em>Pride and Prejudice</em> and Word Embedding Distance”</a>; Michael Gavin, <a href="http://modelingliteraryhistory.org/2015/09/18/the-arithmetic-of-concepts-a-response-to-peter-de-bolla/">“The Arithmetic of Concepts: A Response to Peter de Bolla”</a>, Sept. 18, 2015; Ben Schmidt, <a href="http://bookworm.benschmidt.org/posts/2015-10-25-Word-Embeddings.html">“Vector Space Models for the Digital Humanities”</a>, Oct. 25, 2015.</p> <p><a id="fn4"></a>     5. Barthes, 18.</p> <p><a id="fn5"></a>     6. See Elaine Freedgood and Cannon Schmitt, “Denotatively, Technically, Literally,” <em>Representations</em> 125.1 (Winter, 2014), 1-14; and Henry Turner, <em>The English Renaissance Stage: Geometry, Poetics, and the Practical Spatial Arts, 1580-1630</em> (Oxford: Oxford University Press, 2006), 114-154.</p> <p><a id="fn6"></a>    7. The model was trained on context windows spanning 5 words on either side of a given term, for words appearing at least 40 times in the corpus. I removed stopwords (using the standard nltk stopword list), but I did not stem or lemmatize the corpus. The model and a csv of the model contents can be downloaded <a href="https://www.dropbox.com/sh/vg0v4evj3ru4ziz/AAA60zxXvN_NYTMtDzmNx508a?dl=0">here</a>. Since I created the model, the Visualizing English Print team has publicly released a <a href="http://graphics.cs.wisc.edu/WP/vep/tcp/">version</a> of the EEBO-TCP corpus with standardized spelling, which, I expect, would produce a more accurate model for word sense disambiguation.</p> <p><a id="fn7"></a>    8. For arguments supporting count-based approaches to semantic modeling, see Omer Levy, et al., “Improved Distributional Similarity with Lessons Learned from Word Embeddings,” <em>Transactions of the Association for Computational Linguistics</em> 3 (2015): 211-225; Omer Levy and Yoav Goldberg, “Linguistic Regularities in Sparse and Explicit Word Representations,” <em>Proceedings of the Eighteenth Conference on Computational Language Learning</em> (2014): 171-180. For the rationale behind predictive modeling, see Marco Baroni, et al., “Don’t count, predict! A systematic comparison of context-counting vs. context-predicting semantic vectors,” <em>Proceedings of Association for Computational Linguistics</em> (2014); as well as the paper that introduced the <code class="language-plaintext highlighter-rouge">word2vec</code> algorithm, Tomas Mikolov, et al., “Efficient Estimation of Word Representations in Vector Space,” (2013), <a href="http://arxiv.org/abs/1301.3781">http://arxiv.org/abs/1301.3781</a>.</p> <p><a id="fn8"></a>     9. There is still a lot work to do in using word distribution models to analyze phrases and sentences. <code class="language-plaintext highlighter-rouge">Word2vec</code> has been used to identify words that tend to appear in phrases. See Mikolov, et al., <a href="https://arxiv.org/abs/1310.4546">“Distributed Representations of Words and Phrases and their Compositionality,”</a> (Oct., 2013). Yet I have not seen persuasive results in using such models to analyze sentence similarity. My own attempts to use <code class="language-plaintext highlighter-rouge">word2vec</code> to analyze sentence similarity in the EEBO-TCP corpus has not worked at all. My standard deviation measure represents a somewhat crude but effective method for looking at the semantic similarities between words in context windows. I’m sure that there will be additional approaches that might be more useful in the future. Here’s just some information on results from using the measure in this experiment. The mean standard deviation value for each word in the subset 1678-1682 corpus (averaged across all of the context windows of each word) is <code class="language-plaintext highlighter-rouge">0.11229</code>. The mean for the top 150 terms that I present here is <code class="language-plaintext highlighter-rouge">0.139412</code>, which is a little more than five standard deviations above the mean. While these terms stand out from the rest, it is of course true that there is only a relative difference between the lexical variation appearing in the context windows of the top terms and those of the rest of the words in the model. Above I focus on the contexts of the top terms, but the terms with the lowest values for the measure also indicate its efficacy. For instance two of the bottom terms are <em>oge</em> and <em>ordeining</em>, which like many of the top terms are difficult to contextualize at first glance. In the subset, <em>Oge</em> primarily occurs in Irish genealogies in which formulaic phrases appear with great frequency, and the resulting context windows contain a lot of repeated words. Similarly, <em>ordeining</em> largely appears in formulaic phrases in religious texts, most notably <em>the power of ordeining others</em>. For a prime example, see Henry Dodwell, <a href="http://quod.lib.umich.edu/e/eebo/A36253.0001.001/1:29?amt2=120;amt3=40;c=eebo;c=eebo2;g=eebogroup;rgn=div1;view=toc;xc=1;q1=ordeining;op2=near;q2=others;op3=near;q3=power"><em>Separation of churches from episcopal government, as practised by the present non-conformists, proved schismatical from such principles as are least controverted and do withal most popularly explain the sinfulness and mischief of schism</em></a> (London: 1679). Finally, using my subsetting method produces the additional issue of reducing the size of the corpus under analysis and thus allowing texts with idiosyncratic linguistic structures to dominate. The subset corpus contains 4,370 texts. I think working with count-based distribution models might make this problem easier to avoid, although it may introduce other challenges regarding the size of the model.</p> <p><a id="fn9"></a>     10. Roland Barthes, “The Reality Effect,” <em>The Rustle of Language</em> (Berkeley and Los Angeles: University of California, 1989), 141.</p> <p><a id="fn10"></a>     11. Freedgood and Schmitt, 5.</p> <p><a id="fn11"></a>     12. K. G. Davies, <em>The North Atlantic World in the Seventeenth Century</em> (Minneapolis: University of Minnesota Press, 1974), 157.</p> <p><a id="fn12"></a>     13. Bruno Latour, “Circulating Reference: Sampling the Soil in the Amazon Forest,” <em>Pandora’s Hope: Essays on the Reality of Science Studies</em> (Cambridge: Harvard University Press, 1999), 24.</p> <p><a id="fn13"></a>     14. Arielle Seiber and Henry Turner, “Mathematics and the Imagination: A Brief Introduction,” <em>Configurations</em> 17 (2009), 12.</p> <table style="border-style: hidden; border-collapse: collapse;"> </table>]]></content><author><name></name></author><category term="blog"/><category term="language"/><category term="vectors"/><summary type="html"><![CDATA[What are the conditions under which very different words are brought together in writing? Are varied word combinations predisposed to particular genres or discourses? Are there types of words that could be said to constitute lexical situations that would not otherwise occur? And, when words that are not typically used in the same context co-occur, what are they doing? I am going to report the results of a text analysis experiment designed to begin to address these questions. Recent advances in semantic modeling (from topic modeling to word embeddings) make it relatively easy to describe the statistical likelihood of a given set of words to co-occur. Methods in semantic modeling start from the premises that words tend to occur in particular linguistic contexts, and we can decipher the meaning of an unknown word based upon the words that appear near it. While many humanists (like me) interested in text analysis have begun to explore the mathematics of operationalizing these premises, corpus linguists have been thinking about modeling language in this way since the 1940s and 50s. Early theorist of the “distributional structure” of language, Zellig Harris, explains that, “The perennial man in the street believes that when he speaks he freely puts together whatever elements have the meanings he intends; but he does so only by choosing members of those classes that regularly occur together and in the order in which these classes occur.”1 His contemporary, J. R. Firth, put the claim even more plainly in his now famous formulation: “You shall know a word by the company it keeps.”2 Since these foundational theories, linguists have produced methods for mathematically representing the tendencies of language. In this experiment, I focus on word space models, which represent the distribution of words in a corpus as vectors with hundreds or thousands of dimensions wherein proximity in the vector space corresponds to semantic similarity. The vector position for any given word represents a probabilistic profile regarding the lexical contexts in which one would expect to find that word. As a consequence, word vectors can be added and subtracted to find the words most similar in the model to the resulting composite vector.]]></summary></entry></feed>